# dataengineer
for DataLake with Spark (Sparkify)
ETL Pipeline

Load the credentials from dl.cfg

Load the Data which are in JSON Files(Song Data and Log Data) After loading the JSON Files from S3 

Use Spark process this JSON files and then generate a set of Fact and Dimension Tables

Load back these dimensional process to S3
